{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7991d88c",
   "metadata": {},
   "source": [
    "# Agriculture Detection with PyTorch\n",
    "This notebook focuses on preparing PyTorch datasets and data loaders for the satellite imagery classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3ac8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import importlib\n",
    "import torch.nn as nn\n",
    "\n",
    "# Local imports\n",
    "import utils.main_utils as main_utils\n",
    "importlib.reload(main_utils)\n",
    "from utils.main_utils import (\n",
    "    check_skillnetwork_extraction, \n",
    "    shuffle_data,\n",
    "    get_random_sample_image\n",
    ")\n",
    "import utils.pytorch_ai_utils as pytorch_ai_utils\n",
    "importlib.reload(pytorch_ai_utils)\n",
    "from utils.pytorch_ai_utils import (\n",
    "    create_pytorch_custom_dataset, \n",
    "    create_pytorch_dataset, \n",
    "    display_pytorch_batch, \n",
    "    set_pytorch_seed, \n",
    "    set_pytorch_processing_env,\n",
    "    worker_init_fn, \n",
    "    create_pytorch_loaders,\n",
    "    build_pytorch_model,\n",
    "    display_pytorch_history,\n",
    "    pytorch_training_loop,\n",
    "    evaluate_pytorch_model,\n",
    "    visualize_satellite_agriculture,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8d6925",
   "metadata": {},
   "source": [
    "## Download and Extract Data\n",
    "Ensure the satellite imagery dataset is available locally before constructing PyTorch datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd899ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract data\n",
    "url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/4Z1fwRR295-1O3PMQBH6Dg/images-dataSAT.tar'\n",
    "extract_dir = './data/pytorch_data/'\n",
    "model_dir = './models/'\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "dataset_path = os.path.join(extract_dir, 'images_dataSAT')\n",
    "await check_skillnetwork_extraction(extract_dir, url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b60d94",
   "metadata": {},
   "source": [
    "## Prepare Image Paths and Labels\n",
    "Collect class-specific file paths and labels for use with PyTorch datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a71ec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather image paths and labels\n",
    "base_dir = './data/pytorch_data/images_dataSAT/'\n",
    "dir_non_agri_name = os.path.join(base_dir, 'class_0_non_agri')\n",
    "dir_agri_name = os.path.join(base_dir, 'class_1_agri')\n",
    "\n",
    "all_image_paths, all_labels = shuffle_data(dir_non_agri_name, dir_agri_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef469a2",
   "metadata": {},
   "source": [
    "## Build PyTorch Datasets and Data Loaders\n",
    "Instantiate both custom and `ImageFolder`-based datasets, then create loaders for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828b0949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch datasets and loaders and display batches\n",
    "batch_size = 8\n",
    "custom_loader = create_pytorch_custom_dataset(\n",
    "    base_dir,\n",
    "    dir_non_agri_name,\n",
    "    dir_agri_name,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "imagefolder_loader = create_pytorch_dataset(base_dir, batch_size=batch_size)\n",
    "display_pytorch_batch(custom_loader, batch_size, title='Custom Loader')\n",
    "display_pytorch_batch(imagefolder_loader, batch_size, title='ImageFolder Loader')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751c629c",
   "metadata": {},
   "source": [
    "## Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8859d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "set_pytorch_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796b202d",
   "metadata": {},
   "source": [
    "## Initialize PyTorch Processing Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a58f6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = set_pytorch_processing_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88731b3b",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9915b5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and Training Hyperparameters\n",
    "img_size = 64                          # Image width and height\n",
    "batch_size = 128                       # Number of samples per gradient update\n",
    "lr = .001                              # Learning rate for the optimizer\n",
    "epochs = 3                             # Number of times to iterate over the entire dataset\n",
    "padding = 'same'                       # Padding type for convolutional layers ('same' or 0, 1, 2, ...)\n",
    "loss_function = nn.CrossEntropyLoss()  # Loss function for binary classification (CrossEntropyLoss or BCEWithLogitsLoss)\n",
    "num_classes = 2                        # Number of output classes (2 for CrossEntropyLoss, 1 for BCEWithLogitsLoss)\n",
    "num_workers = 0                        # Number of worker processes for data loading\n",
    "train_split = .8                       # Fraction of data to use for training\n",
    "shuffle = True                         # Whether to shuffle the data\n",
    "model_name = os.path.join(             # Name of the file to save the model\n",
    "    model_dir, \n",
    "    'pytorch_model.pth'\n",
    ")\n",
    "\n",
    "# Architectural Hyperparameters\n",
    "n_channels = 3                         # Number of input image channels (3 for RGB)\n",
    "conv_block_num = 4                     # Number of convolutional blocks\n",
    "dense_block_num = 2                    # Number of dense blocks\n",
    "filter_base = 32                       # Base number of filters for convolutional layers\n",
    "unit_base = 128                        # Base number of units for dense layers\n",
    "kernel_size = 5                        # Kernel size for convolutional layers\n",
    "pool_size = 2                          # Pool size for MaxPooling layers\n",
    "dropout = 0.4                          # Dropout rate for regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5198199b",
   "metadata": {},
   "source": [
    "## Create Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a2b4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = create_pytorch_loaders(\n",
    "    dataset_path=dataset_path, \n",
    "    worker=worker_init_fn,\n",
    "    img_size=img_size, \n",
    "    batch_size=batch_size, \n",
    "    train_split=train_split, \n",
    "    shuffle=shuffle, \n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8566f1d",
   "metadata": {},
   "source": [
    "## Build PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d123ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_pytorch_model(\n",
    "    conv_block_num=conv_block_num,\n",
    "    dense_block_num=dense_block_num,\n",
    "    filter_base=filter_base,\n",
    "    unit_base=unit_base,\n",
    "    kernel_size=kernel_size,\n",
    "    padding=padding,\n",
    "    pool_size=pool_size,\n",
    "    dropout=dropout,\n",
    "    n_channels=n_channels,\n",
    "    num_classes=num_classes, \n",
    "    device=device, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd16e13b",
   "metadata": {},
   "source": [
    "## Train PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5de1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, loss_history, acc_history = pytorch_training_loop(\n",
    "    loss_function=loss_function,\n",
    "    lr=lr,\n",
    "    epochs=epochs, \n",
    "    model=model, \n",
    "    train_loader=train_loader, \n",
    "    val_loader=val_loader,\n",
    "    device=device, \n",
    "    model_name=model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fbd90a",
   "metadata": {},
   "source": [
    "## Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3b5548",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_pytorch_history(\n",
    "    acc_history, \n",
    "    loss_history, \n",
    "    model, \n",
    "    val_loader, \n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b7ac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = 'results/'\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "result_path = os.path.join(result_dir, 'tile_grid_visualization.png')\n",
    "\n",
    "# get one random image path\n",
    "sample_img_path = get_random_sample_image(dir_non_agri_name, dir_agri_name)\n",
    "\n",
    "visualize_satellite_agriculture(\n",
    "    model=model,\n",
    "    dir_non_agri=dir_non_agri_name,\n",
    "    dir_agri=dir_agri_name,\n",
    "    device=device,\n",
    "    grid_size=4,\n",
    "    tile_size=64,\n",
    "    save_path=result_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c766b94",
   "metadata": {},
   "source": [
    "## Display Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b055c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_pytorch_model(model, val_loader, device, model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
